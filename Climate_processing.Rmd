---
title: "Climate_processing"
author: "Simon Marks"
date: "12/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Packages

```{r}
library(tidyverse)
library(lubridate)
library(data.table)
library(openair)
```

#### Helper function `coalesce_join`

**Description**

`coalesce_join` performs a majority of the data aggregation work within the `process_well_data`. The function combines two datasets containing identical non-key variables in varying states of completeness. This allows for the well data compilation to be updated/appended to without worry of overlap with the existing time series in the existing compilation.

**Arguments:**

* `x`, `y` tbls to join
* `by` a character vector of variables to join by. If NULL, the default, *_join() defined by the `join` argument will do a natural join, using all variables with common names across the two tables. A message lists the variables so that you can check they're right (to suppress the message, simply explicitly list the variables that you want to join).
* `suffix` If there are non-joined duplicate variables in x and y, these suffixes will be added to the output to disambiguate them. Should be a character vector of length 2
* `join` type of mutating join supported by `dplyr`
* ... other parameters passed onto methods, for instance, `na_matches` to control how NA values are matched. This is mostly included for robustness.

**Value**

A data frame `tbl_df`

```{r}

coalesce_join <- function(x, y, 
                          by = NULL, suffix = c(".x", ".y"), 
                          join = dplyr::full_join, ...) {
  
    joined <- join(x, y, by = by, suffix = suffix, ...)
    
    # names of desired output
    cols <- dplyr::union(names(x), names(y))
    
    to_coalesce <- names(joined)[!names(joined) %in% cols]
    
    suffix_used <- suffix[ifelse(endsWith(to_coalesce, suffix[1]), 1, 2)]
    
    # remove suffixes and reduplicate
    to_coalesce <- unique(substr(
        to_coalesce, 
        1, 
        nchar(to_coalesce) - nchar(suffix_used)
    ))
    
    coalesced <- purrr::map_dfc(to_coalesce, ~dplyr::coalesce(
        joined[[paste0(.x, suffix[1])]], 
        joined[[paste0(.x, suffix[2])]]
    ))
    
    names(coalesced) <- to_coalesce
    
    dplyr::bind_cols(joined, coalesced)[cols]
}

```

#### Read HOBO U20 atmospheric datafile

**Description**

`read_atm_hobo_u20` reads HOBO u20 produced atmospheric pressure `.csv` files into R. Returns a data.frame usable in `barometric_datafile_correction`'s `baro.data` argument. 

**Arguments**

* `path` path to raw `.csv` atmospheric datafile produced by HOBO U20

**Value**

A data.frame

```{r}

read_atm_hobo_u20 <- function(path){
  
  # Avoid problem of not knowing the number of cols coming from Hobo file (i.e. avoid warning)
  no_of_cols <- readr::read_csv(path, skip = 1, n_max = 1, col_types = cols(.default = col_guess())) %>% 
    ncol()
  
  no_of_cols_drop_at_end <- no_of_cols - 4
  
  data <- readr::read_csv(path, skip = 2, 
                          col_types = paste0("_cdd", stringi::stri_dup("_", no_of_cols_drop_at_end)), 
                          col_names = c("Date", "baro.pressure_psi", "baro.temp_F")) %>% 
    dplyr::mutate(Date = lubridate::mdy_hms(Date)) %>% 
    dplyr::filter(!is.na(baro.pressure_psi))
  
  return(data)
  
}

```

#### Read HOBO climate station datafile

**Description**

`read_climate` reads HOBOclimate station produced `.csv` files into R. 

**Arguments**

* `path` path to raw `.csv` climate datafile produced by HOBO station at either Control or Rock Creek meadows

**Value**

A data.frame

```{r}

## function for reading climate data from raw file- snow or no snow in file (there were two file configurations in the raw data)

read_climate <- function(path){
  
  col_names <- readr::read_lines(path, skip = 1, n_max = 1) %>% 
    stringr::str_remove_all(pattern = '\"') %>% 
    stringr::str_split(pattern = ",") %>% 
    purrr::pluck(1) %>% 
    str_to_lower() %>% 
    str_detect("snow")
  
  if(TRUE %in% col_names){
    
    data <- readr::read_csv(path, skip = 2, 
                            col_types = "_cddddddddd", col_names = c("Date", "solar.rad_1", "solar.rad_2", "wind_speed", "gust_speed",
                                                                     "temp_F", "RH", "rain_in", "snowdepth_in", "current")) %>% 
      dplyr::mutate(Date = lubridate::mdy_hms(Date))
    
    return(data)
    
  } else {
    
    data <- readr::read_csv(path, skip = 2, 
                            col_types = "_cddddd", col_names = c("Date", "solar.rad_1", "wind_speed", "gust_speed", 
                                                                     "temp_F", "RH")) %>% 
      dplyr::mutate(Date = lubridate::mdy_hms(Date))
    
    return(data)
    
  }
  
}
  
```

#### Main Function `compile_atm_data`

**Description**

`compile_atm_data` takes a folder containing raw `.csv` atmospheric data files from one meadow site and performs data compilation, appending to an existing compilation for that meadow site if prompted. Outputs a written `.csv` file.

**Arguments**

* `path` path to folder containing raw `.csv` atmospheric data files. This provided path is where the compilation .csv will be written to.
* `prev_compile` previous atm data compilation. By default this is set to `NULL` 
* `written_file` name of produced compilation file, must be quoted and end with `.csv`

**Value**

A .csv file written to `path`

```{r}

compile_atm_data <- function(path, prev_compile = NULL, written_file_name){
  
  if(!stringr::str_detect(written_file_name, pattern = ".csv")){
    stop("provided written file name must end with .csv")
  }
  
  ## Create char. vector of file names w/ directory path prepended contained in provided path
  
  files <- list.files(path, full.names = TRUE)
  
  ## Creates list of clean/standardized data (data frames) for all those provided in the path using `read_atm_hobo_u20` function
  
  listed_files <- purrr::map(files, read_atm_hobo_u20)
  
  # Keeps files grouped by instrument and orders data chronologically. Duplicate observations are removed.
  compiled <- dplyr::bind_rows(listed_files) %>% 
    dplyr::distinct() %>%
    # `dplyr::arrange` would not function properly here
    do(data.frame(with(data = .,.[order(Date),])))
  
  ## Compiles well data using only those files provided in the path
  
  if(is.null(prev_compile)){
    
    compiled <- compiled %>% 
      dplyr::mutate(Date = as.character(Date))
    
    # Write out compiled file from provided files only 
    readr::write_csv(compiled, path = paste0(path, "/", written_file_name))
    
    ## When prev_compile file is provided, the files provided in the path are appended to the previously compiled file
    # Performs coalescing join- user does not have to worry about feeding in data that has been previously compiled
  } else {
    
    appended_compile <- prev_compile %>%
      coalesce_join(compiled, by = "Date") %>% 
      do(data.frame(with(data = .,.[order(Date),]))) %>%
      dplyr::distinct() %>% 
      purrr::discard(~all(is.na(.))) %>% 
      dplyr::mutate(Date = as.character(Date))
    
    # Write out appended compile file
    readr::write_csv(appended_compile, path = paste0(path, "/", written_file_name))

  }
  
}

```

#### Main Function `compile_climate_data`

**Description**

`compile_climate_data` takes a folder containing raw `.csv` climate data files from one meadow site and performs data compilation, appending to an existing compilation for that meadow site if prompted. Outputs a written `.csv` file.

**Arguments**

* `path` path to folder containing raw `.csv` climate data files. This provided path is where the compilation .csv will be written to.
* `prev_compile` previous climate data compilation. By default this is set to `NULL` 
* `written_file` name of produced compilation file, must be quoted and end with `.csv`

**Value**

A .csv file written to `path`

```{r}

compile_climate_data <- function(path, prev_compile = NULL, written_file_name){
  
  if(!stringr::str_detect(written_file_name, pattern = ".csv")){
    stop("provided written file name must end with .csv")
  }
  
  ## Create char. vector of file names w/ directory path prepended contained in provided path
  
  files <- list.files(path, full.names = TRUE)
  
  ## Creates list of clean/standardized data (data frames) for all those provided in the path using `read_climate` function
  
  listed_files <- purrr::map(files, read_climate)
  
  # Keeps files grouped by instrument and orders data chronologically. Duplicate observations are removed.
  compiled <- dplyr::bind_rows(listed_files) %>% 
    dplyr::distinct() %>%
    # `dplyr::arrange` would not function properly here
    do(data.frame(with(data = .,.[order(Date),])))
  
  ## Compiles well data using only those files provided in the path
  
  if(is.null(prev_compile)){
    
    compiled <- compiled %>% 
      dplyr::mutate(Date = as.character(Date))
    
    # Write out compiled file from provided files only 
    readr::write_csv(compiled, path = paste0(path, "/", written_file_name))
    
    ## When prev_compile file is provided, the files provided in the path are appended to the previously compiled file
    # Performs coalescing join- user does not have to worry about feeding in data that has been previously compiled
  } else {
    
    appended_compile <- prev_compile %>%
      coalesce_join(compiled, by = "Date") %>% 
      do(data.frame(with(data = .,.[order(Date),]))) %>%
      dplyr::distinct() %>% 
      purrr::discard(~all(is.na(.))) %>% 
      dplyr::mutate(Date = as.character(Date))
    
    # Write out appended compile file
    readr::write_csv(appended_compile, path = paste0(path, "/", written_file_name))

  }
  
}

```